import os
import streamlit as st
import pandas as pd
import requests
import base64
import hashlib
from io import BytesIO
from datetime import datetime, timedelta
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, PatternFill, Border, Side, Font


GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]  # åœ¨ Streamlit Cloud ç”¨ secrets
REPO_NAME = "TTTriste06/semi"
BRANCH = "main"

CONFIG = {
    "output_file": f"è¿è¥æ•°æ®è®¢å•-åœ¨åˆ¶-åº“å­˜æ±‡æ€»æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
    "selected_month": None,
    "pivot_config": {
        "èµ›å“-æœªäº¤è®¢å•.xlsx": {
            "index": ["æ™¶åœ†å“å", "è§„æ ¼", "å“å"],
            "columns": "é¢„äº¤è´§æ—¥",
            "values": ["è®¢å•æ•°é‡", "æœªäº¤è®¢å•æ•°é‡"],
            "aggfunc": "sum",
            "date_format": "%Y-%m"
        },
        "èµ›å“-æˆå“åœ¨åˆ¶.xlsx": {
            "index": ["å·¥ä½œä¸­å¿ƒ", "å°è£…å½¢å¼", "æ™¶åœ†å‹å·", "äº§å“è§„æ ¼", "äº§å“å“å"],
            "columns": "é¢„è®¡å®Œå·¥æ—¥æœŸ",
            "values": ["æœªäº¤"],
            "aggfunc": "sum",
            "date_format": "%Y-%m"
        },
        "èµ›å“-CPåœ¨åˆ¶.xlsx": {
            "index": ["æ™¶åœ†å‹å·", "äº§å“å“å"],
            "columns": "é¢„è®¡å®Œå·¥æ—¥æœŸ",
            "values": ["æœªäº¤"],
            "aggfunc": "sum",
            "date_format": "%Y-%m"
        },
        "èµ›å“-æˆå“åº“å­˜.xlsx": {
            "index": ["WAFERå“å", "è§„æ ¼", "å“å"],
            "columns": "ä»“åº“åç§°",
            "values": ["æ•°é‡"],
            "aggfunc": "sum"
        },
        "èµ›å“-æ™¶åœ†åº“å­˜.xlsx": {
            "index": ["WAFERå“å", "è§„æ ¼"],
            "columns": "ä»“åº“åç§°",
            "values": ["æ•°é‡"],
            "aggfunc": "sum"
        }
    }
}

def upload_to_github(file, path_in_repo, commit_message):
    api_url = f"https://api.github.com/repos/{REPO_NAME}/contents/{path_in_repo}"
    
    file.seek(0)  # ç¡®ä¿æŒ‡é’ˆåœ¨å¼€å¤´
    file_content = file.read()
    encoded_content = base64.b64encode(file_content).decode('utf-8')

    # å…ˆè·å–æ–‡ä»¶ SHAï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    response = requests.get(api_url, headers={"Authorization": f"token {GITHUB_TOKEN}"})
    if response.status_code == 200:
        sha = response.json()['sha']
    else:
        sha = None

    # æ„é€  payload
    payload = {
        "message": commit_message,
        "content": encoded_content,
        "branch": BRANCH
    }
    if sha:
        payload["sha"] = sha

    # ä¸Šä¼ æ–‡ä»¶
    response = requests.put(api_url, json=payload, headers={"Authorization": f"token {GITHUB_TOKEN}"})

    # ç»“æœåé¦ˆ
    if response.status_code in [200, 201]:
        st.success(f"{path_in_repo} ä¸Šä¼ æˆåŠŸï¼")
    else:
        st.error(f"ä¸Šä¼ å¤±è´¥: {response.json()}")


def preprocess_mapping_file(df):
    # åªå–å‰6åˆ—
    df = df.iloc[:, :6]
    # é‡å‘½ååˆ—
    df.columns = ['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å']
    return df


def download_mapping_from_github(path_in_repo):
    api_url = f"https://api.github.com/repos/{REPO_NAME}/contents/{path_in_repo}"
    response = requests.get(api_url, headers={
        "Authorization": f"token {GITHUB_TOKEN}"
    })
    if response.status_code == 200:
        content = base64.b64decode(response.json()['content'])
        df = pd.read_excel(pd.io.common.BytesIO(content))
        if df.shape[1] >= 6:
            df = preprocess_mapping_file(df)
        else:
            st.warning(f"mapping_file.xlsx åˆ—æ•°ä¸è¶³ï¼šåªå‘ç° {df.shape[1]} åˆ—ï¼Œéœ€è¦è‡³å°‘ 6 åˆ—")
            df = pd.DataFrame(columns=['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å'])
        return df
    else:
        st.warning("GitHub ä¸Šæ‰¾ä¸åˆ° mapping_file.xlsxï¼Œç”¨é»˜è®¤è¡¨æˆ–è¯·å…ˆä¸Šä¼ ")
        return pd.DataFrame(columns=['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å'])

def download_excel_from_github(url, token=None):
    headers = {"Authorization": f"token {token}"} if token else {}
    response = requests.get(url, headers=headers)
    content_type = response.headers.get('Content-Type', '')

    # æ£€æŸ¥æ–‡ä»¶æ˜¯ä¸æ˜¯ Excel
    if 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' not in content_type:
        raise ValueError("ä¸‹è½½çš„ä¸æ˜¯ Excel æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ GitHub é“¾æ¥æˆ–æƒé™")

    return pd.read_excel(BytesIO(response.content))

def download_backup_file(file_name):
    api_url = f"https://api.github.com/repos/{REPO_NAME}/contents/{file_name}"
    headers = {"Authorization": f"token {GITHUB_TOKEN}"}
    response = requests.get(api_url, headers=headers)

    if response.status_code != 200:
        st.warning(f"âš ï¸ æ— æ³•ä¸‹è½½ {file_name}ï¼ŒGitHub è¿”å›ç  {response.status_code}")
        return pd.DataFrame()  # è¿”å›ç©º DataFrameï¼Œä¿è¯ä¸»ç¨‹åºä¸å´©æºƒ

    content = response.json().get('content')
    if not content:
        st.warning(f"âš ï¸ {file_name} æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–è§£æå¤±è´¥")
        return pd.DataFrame()

    file_bytes = BytesIO(base64.b64decode(content))

    try:
        df = pd.read_excel(file_bytes)
    except Exception as e:
        st.warning(f"âš ï¸ {file_name} è§£æ Excel å¤±è´¥ï¼š{e}ï¼Œå°†åˆ›å»ºç©º sheetã€‚")
        return pd.DataFrame()

    return df
        
def process_date_column(df, date_col, date_format):
    if pd.api.types.is_numeric_dtype(df[date_col]):
        df[date_col] = df[date_col].apply(lambda x: datetime(1899, 12, 30) + timedelta(days=float(x)))
    else:
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df[f'{date_col}_å¹´æœˆ'] = df[date_col].dt.strftime(date_format)
    return df

def apply_mapping_and_merge(df, mapping_df):
    mapping_df = mapping_df.dropna()
    
    df = df.merge(
        mapping_df,
        how='left',
        left_on=['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å'],
        right_on=['æ—§æ™¶åœ†å“å', 'æ—§è§„æ ¼', 'æ—§å“å']
    )
    
    df['æ™¶åœ†å“å'] = df['æ–°æ™¶åœ†å“å'].combine_first(df['æ™¶åœ†å“å'])
    df['è§„æ ¼'] = df['æ–°è§„æ ¼'].combine_first(df['è§„æ ¼'])
    df['å“å'] = df['æ–°å“å'].combine_first(df['å“å'])
    
    df.drop(columns=['æ—§æ™¶åœ†å“å', 'æ—§è§„æ ¼', 'æ—§å“å', 'æ–°æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å'], inplace=True)
    
    group_cols = [col for col in df.columns if col not in df.select_dtypes(include='number').columns]
    agg_cols = df.select_dtypes(include='number').columns.tolist()
    df_merged = df.groupby(group_cols, as_index=False)[agg_cols].sum()
    
    return df_merged

def create_pivot(df, config, filename, mapping_df=None):
    if 'date_format' in config:
        config = config.copy()
        config['columns'] = f"{config['columns']}_å¹´æœˆ"
    pivoted = pd.pivot_table(df, index=config['index'], columns=config['columns'], values=config['values'],
                             aggfunc=config['aggfunc'], fill_value=0)
    pivoted.columns = [f"{col[0]}_{col[1]}" if isinstance(col, tuple) else col for col in pivoted.columns]
    pivoted = pivoted.reset_index()

    if mapping_df is not None and filename == "èµ›å“-æœªäº¤è®¢å•.xlsx":
        pivoted = apply_mapping_and_merge(pivoted, mapping_df)

    if CONFIG['selected_month'] and filename == "èµ›å“-æœªäº¤è®¢å•.xlsx":
        history_cols = [col for col in pivoted.columns if '_' in col and col.split('_')[-1][:4].isdigit() and col.split('_')[-1] < CONFIG['selected_month']]
        history_order_cols = [col for col in history_cols if 'è®¢å•æ•°é‡' in col and 'æœªäº¤è®¢å•æ•°é‡' not in col]
        history_pending_cols = [col for col in history_cols if 'æœªäº¤è®¢å•æ•°é‡' in col]
        if history_order_cols:
            pivoted['å†å²è®¢å•æ•°é‡'] = pivoted[history_order_cols].sum(axis=1)
        if history_pending_cols:
            pivoted['å†å²æœªäº¤è®¢å•æ•°é‡'] = pivoted[history_pending_cols].sum(axis=1)
        pivoted.drop(columns=history_cols, inplace=True)
        fixed_cols = [col for col in pivoted.columns if col not in ['å†å²è®¢å•æ•°é‡', 'å†å²æœªäº¤è®¢å•æ•°é‡']]
        if 'å†å²è®¢å•æ•°é‡' in pivoted.columns:
            fixed_cols.insert(len(config['index']), 'å†å²è®¢å•æ•°é‡')
        if 'å†å²æœªäº¤è®¢å•æ•°é‡' in pivoted.columns:
            fixed_cols.insert(len(config['index']) + 1, 'å†å²æœªäº¤è®¢å•æ•°é‡')
        pivoted = pivoted[fixed_cols]

    return pivoted

def adjust_column_width(writer, sheet_name, df):
    worksheet = writer.sheets[sheet_name]
    for idx, col in enumerate(df.columns, 1):
        max_len = df[col].astype(str).str.len().max()
        header_len = len(str(col))
        width = max(max_len, header_len) * 1.2 + 5
        worksheet.column_dimensions[get_column_letter(idx)].width = min(width, 50)

def add_black_border(ws, row_count, col_count):
    thin = Side(border_style="thin", color="000000")
    border = Border(top=thin, left=thin, right=thin, bottom=thin)
    for row in ws.iter_rows(min_row=1, max_row=row_count, min_col=1, max_col=col_count):
        for cell in row:
            cell.border = border

def main():
    st.set_page_config(
        page_title='æˆ‘æ˜¯æ ‡é¢˜',
        page_icon=' ',
        layout='wide'
    )

    with st.sidebar:
        st.title("æ¬¢è¿æ¥åˆ°æˆ‘çš„åº”ç”¨")
        st.markdown('---')
        st.markdown('è¿™æ˜¯å®ƒçš„ç‰¹æ€§ï¼š\n- feature 1\n- feature 2\n- feature 3')

    st.title('Excel æ•°æ®å¤„ç†ä¸æ±‡æ€»å·¥å…·')
    selected_month = st.text_input('è¯·è¾“å…¥æˆªè‡³æœˆä»½ï¼ˆå¦‚ 2025-03ï¼Œå¯é€‰ï¼‰')
    CONFIG['selected_month'] = selected_month if selected_month else None

    uploaded_files = st.file_uploader('ä¸Šä¼  Excel æ–‡ä»¶ï¼ˆ5ä¸ªæ–‡ä»¶ï¼‰', type=['xlsx'], accept_multiple_files=True)
    pred_file = st.file_uploader('ä¸Šä¼ é¢„æµ‹æ–‡ä»¶', type=['xlsx'], key='pred_file')
    safety_file = st.file_uploader('ä¸Šä¼ å®‰å…¨åº“å­˜æ–‡ä»¶', type=['xlsx'], key='safety_file')
    mapping_file = st.file_uploader('ä¸Šä¼ æ–°æ—§æ–™å·æ–‡ä»¶', type=['xlsx'], key='mapping_file')

    # åŠ è½½ mapping_file DataFrame
    mapping_df = None
    if mapping_file:
        mapping_df = pd.read_excel(mapping_file)
        mapping_df = preprocess_mapping_file(mapping_df)

    if pred_file:
        upload_to_github(pred_file, "pred_file.xlsx", "ä¸Šä¼ é¢„æµ‹æ–‡ä»¶")
    if safety_file:
        upload_to_github(safety_file, "safety_file.xlsx", "ä¸Šä¼ å®‰å…¨åº“å­˜æ–‡ä»¶")
    if mapping_file:
        upload_to_github(mapping_file, "mapping_file.xlsx", "ä¸Šä¼ æ–°æ—§æ–™å·æ–‡ä»¶")

    if st.button('æäº¤å¹¶ç”ŸæˆæŠ¥å‘Š') and uploaded_files:
        with pd.ExcelWriter(CONFIG['output_file'], engine='openpyxl') as writer:
            # ç”¨äºå­˜å‚¨æœªäº¤è®¢å•çš„å‰ä¸‰åˆ—æ•°æ®
            unfulfilled_orders_summary = pd.DataFrame()
            df_safety = pd.DataFrame()

            for f in uploaded_files:
                filename = f.name
                if filename not in CONFIG['pivot_config']:
                    st.warning(f"è·³è¿‡æœªé…ç½®çš„æ–‡ä»¶: {filename}")
                    continue

                df = pd.read_excel(f)
                config = CONFIG['pivot_config'][filename]

                if 'date_format' in config and config['columns'] in df.columns:
                    df = process_date_column(df, config['columns'], config['date_format'])

                pivoted = create_pivot(df, config, filename, mapping_df)
                sheet_name = filename[:30].rstrip('.xlsx')
                pivoted.to_excel(writer, sheet_name=sheet_name, index=False)
                adjust_column_width(writer, sheet_name, pivoted)

                # ä¿å­˜æœªäº¤è®¢å•çš„å‰ä¸‰åˆ—ï¼ˆå»é‡ï¼‰
                if filename == "èµ›å“-æœªäº¤è®¢å•.xlsx":
                    cols_to_copy = [col for col in pivoted.columns if col in ["æ™¶åœ†å“å", "è§„æ ¼", "å“å"]]
                    unfulfilled_orders_summary = pivoted[cols_to_copy].drop_duplicates()
                    pending_pivoted = pivoted.copy()

            # å†™å…¥å®‰å…¨åº“å­˜ sheet
            if safety_file:
                df_safety = pd.read_excel(safety_file)
            else:
                df_safety = download_backup_file("safety_file.xlsx")
            df_safety.to_excel(writer, sheet_name='èµ›å“-å®‰å…¨åº“å­˜', index=False)
            adjust_column_width(writer, 'èµ›å“-å®‰å…¨åº“å­˜', df_safety)

            # å†™å…¥é¢„æµ‹æ–‡ä»¶ sheet
            if pred_file:
                df_pred = pd.read_excel(pred_file)
            else:
                df_pred = download_backup_file("pred_file.xlsx")
            df_pred.to_excel(writer, sheet_name='èµ›å“-é¢„æµ‹', index=False)
            adjust_column_width(writer, 'èµ›å“-é¢„æµ‹', df_pred)

            # å†™å…¥æ–°æ—§æ–™å·æ–‡ä»¶ sheet
            # === åœ¨å¤„ç†æˆå“åœ¨åˆ¶ä¹‹å‰ï¼Œé‡æ–°åŠ è½½ mapping_file å…¨è¡¨ ===
            if mapping_file:
                df_full_mapping = pd.read_excel(mapping_file)
                
                # è®¾ç½®åˆ—åï¼ˆå‡è®¾ Excel é‡Œæœ‰9åˆ—ï¼Œå«å°è£…å‚ã€PCã€åŠæˆå“ï¼‰
                df_full_mapping.columns = ['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å', 'å°è£…å‚', 'PC', 'åŠæˆå“']
            else:
                df_full_mapping = download_backup_file("mapping_file.xlsx")
                df_full_mapping.columns = ['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å', 'å°è£…å‚', 'PC', 'åŠæˆå“']
            
            # å†™å…¥æ–°æ—§æ–™å·æ–‡ä»¶ sheet
            if mapping_file:
                df_mapping = pd.read_excel(mapping_file, header = 1)
            else:
                df_mapping = download_backup_file("mapping_file.xlsx")
           
            # ç¬¬3è¡Œå¼€å§‹å†™å…¥æ•°æ®ï¼ˆè·³è¿‡ç¬¬1ã€2è¡Œï¼‰
            df_mapping.to_excel(writer, sheet_name='èµ›å“-æ–°æ—§æ–™å·', index=False, header=False, startrow=2)
            
            # è·å– worksheet
            ws = writer.book['èµ›å“-æ–°æ—§æ–™å·']
            ws.delete_rows(0)

            # å†™å…¥ç¬¬2è¡Œè¡¨å¤´ï¼ˆDataFrame çš„åˆ—åï¼‰
            for col_idx, col_name in enumerate(df_mapping.columns, start=1):
                ws.cell(row=2, column=col_idx, value=col_name)
                ws.cell(row=2, column=col_idx).alignment = Alignment(horizontal='center', vertical='center')
                ws.cell(row=2, column=col_idx).font = Font(bold=True)
            
            # å†™å…¥ç¬¬1è¡Œå¤§æ ‡é¢˜ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
            ws.merge_cells('A1:C1')
            ws['A1'] = 'æ—§'
            ws.merge_cells('D1:F1')
            ws['D1'] = 'æ–°'
            
            # è®¾ç½®ç¬¬1è¡Œå¡«å……é¢œè‰²ã€å±…ä¸­ã€åŠ ç²—
            yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')
            green_fill = PatternFill(start_color='00FF00', end_color='00FF00', fill_type='solid')
            
            for cell in ['A1', 'B1', 'C1']:
                ws[cell].fill = yellow_fill
            for cell in ['D1', 'E1', 'F1']:
                ws[cell].fill = green_fill
            
            for col in range(1, len(df_mapping.columns) + 1):
                ws.cell(row=1, column=col).alignment = Alignment(horizontal='center', vertical='center')
                ws.cell(row=1, column=col).font = Font(bold=True)
            
            # å¼€å¯ Excel ç­›é€‰å™¨ï¼ˆç¬¬2è¡Œæ˜¯è¡¨å¤´ï¼‰
            from openpyxl.utils import get_column_letter
            last_col_letter = get_column_letter(len(df_mapping.columns))
            ws.auto_filter.ref = f"A2:{last_col_letter}2"

            # å®šä¹‰æ–°çš„åˆ—å
            new_column_names = ['æ—§è§„æ ¼', 'æ—§å“å', 'æ—§æ™¶åœ†å“å', 'æ–°è§„æ ¼', 'æ–°å“å', 'æ–°æ™¶åœ†å“å', 'å°è£…å‚', 'PC', 'åŠæˆå“']
            
            # ç›´æ¥é‡å‘½åç¬¬äºŒè¡Œæ¯ä¸€åˆ—
            for col_idx, col_name in enumerate(new_column_names, start=1):
                ws.cell(row=2, column=col_idx, value=col_name)
                ws.cell(row=2, column=col_idx).alignment = Alignment(horizontal='center', vertical='center')
                ws.cell(row=2, column=col_idx).font = Font(bold=True)
                
            # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for idx, col in enumerate(ws.columns, 1):
                col_letter = get_column_letter(idx)
                max_length = 0
                for cell in col:
                    try:
                          if cell.value:
                            cell_len = sum(2 if ord(char) > 127 else 1 for char in str(cell.value))
                            max_length = max(max_length, cell_len)
                    except:
                           pass
                ws.column_dimensions[col_letter].width = max_length + 5



            # å†™å…¥æ±‡æ€» sheet
            if not unfulfilled_orders_summary.empty:
                unfulfilled_orders_summary.to_excel(writer, sheet_name='æ±‡æ€»', index=False, startrow=1)
                adjust_column_width(writer, 'æ±‡æ€»', unfulfilled_orders_summary)

                worksheet = writer.book['æ±‡æ€»']
                
                ###å®‰å…¨åº“å­˜
                # é‡å‘½åå®‰å…¨åº“å­˜åˆ—æ–¹ä¾¿åŒ¹é…
                df_safety.rename(columns={
                    'WaferID': 'æ™¶åœ†å“å',
                    'OrderInformation': 'è§„æ ¼',
                    'ProductionNO.': 'å“å'
                }, inplace=True)
                
                # åšä¸€ä¸ªæ ‡å¿—åˆ—ï¼Œè¡¨ç¤ºæ˜¯å¦è¢«ä½¿ç”¨
                df_safety['å·²åŒ¹é…'] = False
                
                # åˆå¹¶å®‰å…¨åº“å­˜æ•°æ®åˆ°æ±‡æ€» sheetï¼ˆunfulfilled_orders_summaryï¼‰
                summary_with_safety = unfulfilled_orders_summary.merge(
                    df_safety[['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å', ' InvWaf', ' InvPart']],
                    on=['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å'], 
                    how='left'
                )
                
                #æ›´æ–°å·²åŒ¹é…æ ‡å¿—
                matched_mask = df_safety.set_index(['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å']).index.isin(
                    summary_with_safety.dropna(subset=[' InvWaf', ' InvPart']).set_index(['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å']).index
                )
                df_safety.loc[matched_mask, 'å·²åŒ¹é…'] = True
                
                #å†™å…¥æ±‡æ€» sheet
                summary_with_safety.rename(columns={' InvWaf': 'InvWafï¼ˆç‰‡ï¼‰', ' InvPart': 'InvPart'}, inplace=True)
                summary_with_safety.to_excel(writer, sheet_name='æ±‡æ€»', index=False, startrow=1)
                adjust_column_width(writer, 'æ±‡æ€»', summary_with_safety)
                
                # åˆå¹¶ D1:E1 å†™å…¥è¡¨å¤´
                worksheet = writer.book['æ±‡æ€»']
                worksheet.merge_cells('D1:E1')
                worksheet['D1'] = 'å®‰å…¨åº“å­˜'
                worksheet['D1'].alignment = Alignment(horizontal='center', vertical='center')
                worksheet['D2'] = 'InvWafï¼ˆç‰‡ï¼‰'
                worksheet['D2'].alignment = Alignment(horizontal='center', vertical='center')
                worksheet['E2'] = 'InvPart'
                worksheet['E2'].alignment = Alignment(horizontal='center', vertical='center')
                
                # æ ‡çº¢æœªè¢«ä½¿ç”¨çš„å®‰å…¨åº“å­˜è¡Œ
                safety_sheet = writer.book['èµ›å“-å®‰å…¨åº“å­˜']
                for row_idx, used in enumerate(df_safety['å·²åŒ¹é…'], start=2):  # Excel ä» 1 å¼€å§‹ï¼Œheader æ˜¯ç¬¬1è¡Œ
                    if not used:
                        for col in range(1, len(df_safety.columns) + 1):
                            safety_sheet.cell(row=row_idx, column=col).fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")

                ###æœªäº¤è®¢å•
                if pending_pivoted is not None:
                    # æ‰¾å‡ºå†å²æœªäº¤è®¢å•å’Œæœªæ¥æ¯æœˆæœªäº¤è®¢å•åˆ—
                    pending_cols = [col for col in pending_pivoted.columns if 'æœªäº¤è®¢å•æ•°é‡_' in col]
                    if 'å†å²æœªäº¤è®¢å•æ•°é‡' in pending_pivoted.columns:
                        all_pending_cols = ['å†å²æœªäº¤è®¢å•æ•°é‡'] + pending_cols
                    else:
                        pending_pivoted['å†å²æœªäº¤è®¢å•æ•°é‡'] = 0
                        all_pending_cols = ['å†å²æœªäº¤è®¢å•æ•°é‡'] + pending_cols
                
                    # è®¡ç®—æ€»å’Œ
                    pending_pivoted['æ€»æœªäº¤è®¢å•'] = pending_pivoted[all_pending_cols].sum(axis=1)
                
                    # æ•´ç†é¡ºåº
                    pending_summary_cols = ['æ€»æœªäº¤è®¢å•'] + all_pending_cols
                    pending_summary_df = pending_pivoted[['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å'] + pending_summary_cols]
                
                    # å®šä½æ±‡æ€» sheet
                    summary_sheet = writer.sheets['æ±‡æ€»']
                    # âœ… å‰ä¸‰åˆ— + å®‰å…¨åº“å­˜ä¸¤åˆ— + 1
                    start_col = unfulfilled_orders_summary.shape[1] + 2 + 1  
                    end_col = start_col + len(pending_summary_cols) - 1
                
                    # âœ… åˆå¹¶ç¬¬ä¸€è¡Œæ‰€æœ‰æ–°åˆ—ï¼ˆä¸è¦†ç›–å®‰å…¨åº“å­˜ï¼‰
                    summary_sheet.merge_cells(start_row=1, start_column=start_col, end_row=1, end_column=end_col)
                    summary_sheet.cell(row=1, column=start_col, value='æœªäº¤è®¢å•').alignment = Alignment(horizontal='center', vertical='center')
                
                    # âœ… å†™å…¥ç¬¬äºŒè¡Œæ ‡é¢˜
                    for idx, col in enumerate(pending_summary_cols, start=start_col):
                        summary_sheet.cell(row=2, column=idx, value=col).alignment = Alignment(horizontal='center', vertical='center')
                
                    # âœ… å†™å…¥ç¬¬ä¸‰è¡ŒåŠä»¥åæ•°æ®
                    for row_idx, row in enumerate(pending_summary_df[pending_summary_cols].itertuples(index=False), start=3):
                        for col_idx, value in enumerate(row, start=start_col):
                            summary_sheet.cell(row=row_idx, column=col_idx, value=value)

                ### é¢„æµ‹
                # === å¤„ç†é¢„æµ‹ sheet ===
                if not df_pred.empty:
                    df_pred.columns = df_pred.iloc[0]
                    df_pred = df_pred.drop([0,0]).reset_index(drop=True)
                
                    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
                    required_columns = ['æ™¶åœ†å“å', 'äº§å“å‹å·', 'ProductionNO.', 'åˆè®¡æ•°é‡', 'åˆè®¡é‡‘é¢']
                    if all(col in df_pred.columns for col in required_columns):
                        # æ„é€  key è¿›è¡ŒåŒ¹é…
                        pred_key = df_pred[['æ™¶åœ†å“å', 'äº§å“å‹å·', 'ProductionNO.']].astype(str)
                        summary_key = unfulfilled_orders_summary[['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å']].astype(str)
                
                        # åœ¨é¢„æµ‹è¡¨ä¸­åŠ åŒ¹é…æ ‡å¿—
                        df_pred['å·²åŒ¹é…'] = False
                
                        # å®šä½æ±‡æ€» sheet
                        summary_sheet = writer.sheets['æ±‡æ€»']
                        start_col = summary_sheet.max_column + 1  # ç©ºç™½åˆ—çš„èµ·ç‚¹
                
                        # åˆå¹¶ç¬¬ä¸€è¡Œå•å…ƒæ ¼å†™å…¥â€œé¢„æµ‹â€
                        summary_sheet.merge_cells(start_row=1, start_column=start_col, end_row=1, end_column=start_col+1)
                        summary_sheet.cell(row=1, column=start_col, value='é¢„æµ‹').alignment = Alignment(horizontal='center', vertical='center')
                        summary_sheet.cell(row=2, column=start_col, value='åˆè®¡æ•°é‡').alignment = Alignment(horizontal='center', vertical='center')
                        summary_sheet.cell(row=2, column=start_col+1, value='åˆè®¡é‡‘é¢').alignment = Alignment(horizontal='center', vertical='center')
                
                        # éå†æ±‡æ€» sheet çš„æ•°æ®è¡Œï¼ˆä»ç¬¬3è¡Œå¼€å§‹ï¼‰
                        for row_idx in range(3, summary_sheet.max_row + 1):
                            summary_wf = summary_sheet.cell(row=row_idx, column=1).value
                            summary_spec = summary_sheet.cell(row=row_idx, column=2).value
                            summary_prod = summary_sheet.cell(row=row_idx, column=3).value
                
                            # æŸ¥æ‰¾é¢„æµ‹è¡¨åŒ¹é…è¡Œ
                            match = df_pred[
                                (df_pred['æ™¶åœ†å“å'].astype(str) == str(summary_wf)) &
                                (df_pred['äº§å“å‹å·'].astype(str) == str(summary_spec)) &
                                (df_pred['ProductionNO.'].astype(str) == str(summary_prod))
                            ]
                
                            if not match.empty:
                                qty = match['åˆè®¡æ•°é‡'].values[0]
                                amt = match['åˆè®¡é‡‘é¢'].values[0]
                                summary_sheet.cell(row=row_idx, column=start_col, value=qty)
                                summary_sheet.cell(row=row_idx, column=start_col+1, value=amt)
                
                                # æ ‡è®°é¢„æµ‹è¡¨çš„è¡Œ
                                df_pred.loc[match.index, 'å·²åŒ¹é…'] = True
                
                        # åœ¨é¢„æµ‹è¡¨ä¸­æ ‡çº¢æœªåŒ¹é…çš„è¡Œ
                        pred_sheet = writer.book['èµ›å“-é¢„æµ‹']
                        for row_idx, matched in enumerate(df_pred['å·²åŒ¹é…'], start=3):  # ä»ç¬¬3è¡Œå¼€å§‹
                            if not matched:
                                for col_idx in range(1, len(df_pred.columns) + 1):
                                    pred_sheet.cell(row=row_idx, column=col_idx).fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")
                
                        # ç»™æ±‡æ€»è¡¨å‰ä¸¤è¡ŒåŠ é»‘æ¡†
                        add_black_border(summary_sheet, 2, summary_sheet.max_column)
                        
                ###æˆå“åº“å­˜
                # === ä»ç”Ÿæˆçš„èµ›å“-æˆå“åº“å­˜ä¸­æå–ä¿¡æ¯ï¼Œå†™å…¥æ±‡æ€» sheet ===
                # å…ˆæ‰¾ç”Ÿæˆçš„èµ›å“-æˆå“åº“å­˜ DataFrame
                product_inventory_pivoted = None
                for f in uploaded_files:
                    if f.name == "èµ›å“-æˆå“åº“å­˜.xlsx":
                        df_product_inventory = pd.read_excel(f)
                        config_inventory = CONFIG['pivot_config']['èµ›å“-æˆå“åº“å­˜.xlsx']
                        if 'date_format' in config_inventory and config_inventory['columns'] in df_product_inventory.columns:
                            df_product_inventory = process_date_column(df_product_inventory, config_inventory['columns'], config_inventory['date_format'])
                        product_inventory_pivoted = create_pivot(df_product_inventory, config_inventory, f.name, mapping_df)
                        break
                
                if product_inventory_pivoted is not None:
                    required_columns = ['WAFERå“å', 'è§„æ ¼', 'å“å', 'æ•°é‡_HOLDä»“', 'æ•°é‡_æˆå“ä»“', 'æ•°é‡_åŠæˆå“ä»“']
                    if all(col in product_inventory_pivoted.columns for col in required_columns):
                        # æ„é€  key
                        inventory_key = product_inventory_pivoted[['WAFERå“å', 'è§„æ ¼', 'å“å']].astype(str)
                        summary_key = unfulfilled_orders_summary[['æ™¶åœ†å“å', 'è§„æ ¼', 'å“å']].astype(str)
                
                        product_inventory_pivoted['å·²åŒ¹é…'] = False
                
                        # å®šä½æ±‡æ€» sheet
                        summary_sheet = writer.sheets['æ±‡æ€»']
                        start_col = summary_sheet.max_column + 1
                
                        # åˆå¹¶ç¬¬ä¸€è¡Œå†™â€œæˆå“åº“å­˜â€
                        summary_sheet.merge_cells(start_row=1, start_column=start_col, end_row=1, end_column=start_col+2)
                        summary_sheet.cell(row=1, column=start_col, value='æˆå“åº“å­˜').alignment = Alignment(horizontal='center', vertical='center')
                        summary_sheet.cell(row=2, column=start_col, value='æ•°é‡_HOLDä»“').alignment = Alignment(horizontal='center', vertical='center')
                        summary_sheet.cell(row=2, column=start_col+1, value='æ•°é‡_æˆå“ä»“').alignment = Alignment(horizontal='center', vertical='center')
                        summary_sheet.cell(row=2, column=start_col+2, value='æ•°é‡_åŠæˆå“ä»“').alignment = Alignment(horizontal='center', vertical='center')
                
                        # éå†æ±‡æ€»è¡¨è¡Œï¼ˆä»ç¬¬3è¡Œå¼€å§‹ï¼‰
                        for row_idx in range(3, summary_sheet.max_row + 1):
                            summary_wf = summary_sheet.cell(row=row_idx, column=1).value
                            summary_spec = summary_sheet.cell(row=row_idx, column=2).value
                            summary_prod = summary_sheet.cell(row=row_idx, column=3).value
                
                            match = product_inventory_pivoted[
                                (product_inventory_pivoted['WAFERå“å'].astype(str) == str(summary_wf)) &
                                (product_inventory_pivoted['è§„æ ¼'].astype(str) == str(summary_spec)) &
                                (product_inventory_pivoted['å“å'].astype(str) == str(summary_prod))
                            ]
                
                            if not match.empty:
                                hold = match['æ•°é‡_HOLDä»“'].values[0]
                                finished = match['æ•°é‡_æˆå“ä»“'].values[0]
                                semi_finished = match['æ•°é‡_åŠæˆå“ä»“'].values[0]
                                summary_sheet.cell(row=row_idx, column=start_col, value=hold)
                                summary_sheet.cell(row=row_idx, column=start_col+1, value=finished)
                                summary_sheet.cell(row=row_idx, column=start_col+2, value=semi_finished)
                
                                product_inventory_pivoted.loc[match.index, 'å·²åŒ¹é…'] = True
                
                        # åœ¨èµ›å“-æˆå“åº“å­˜ sheet ä¸­æ ‡çº¢æœªåŒ¹é…è¡Œ
                        inventory_sheet = writer.book['èµ›å“-æˆå“åº“å­˜']
                        for row_idx, matched in enumerate(product_inventory_pivoted['å·²åŒ¹é…'], start=2):
                            if not matched:
                                for col_idx in range(1, len(product_inventory_pivoted.columns) + 1):
                                    inventory_sheet.cell(row=row_idx, column=col_idx).fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")

                ### æˆå“åœ¨åˆ¶
                semi_finished_value = 0
                semi_row = pd.DataFrame()  # âœ… å…ˆå®šä¹‰ä¸ºç©º DataFrame

                product_in_progress_pivoted = None
                for f in uploaded_files:
                    if f.name == "èµ›å“-æˆå“åœ¨åˆ¶.xlsx":
                        df_product_in_progress = pd.read_excel(f)
                        config_in_progress = CONFIG['pivot_config']['èµ›å“-æˆå“åœ¨åˆ¶.xlsx']
                        if 'date_format' in config_in_progress and config_in_progress['columns'] in df_product_in_progress.columns:
                            df_product_in_progress = process_date_column(df_product_in_progress, config_in_progress['columns'], config_in_progress['date_format'])
                        product_in_progress_pivoted = create_pivot(df_product_in_progress, config_in_progress, f.name, mapping_df)
                        break
                
                if product_in_progress_pivoted is not None:
                    numeric_cols = product_in_progress_pivoted.select_dtypes(include='number').columns.tolist()
                    product_in_progress_pivoted['å·²åŒ¹é…'] = False
                
                    summary_sheet = writer.sheets['æ±‡æ€»']
                    start_col = summary_sheet.max_column + 1
                
                    summary_sheet.merge_cells(start_row=1, start_column=start_col, end_row=1, end_column=start_col + 1)
                    summary_sheet.cell(row=1, column=start_col, value='èµ›å“-æˆå“åœ¨åˆ¶').alignment = Alignment(horizontal='center', vertical='center')
                    summary_sheet.cell(row=2, column=start_col, value='æˆå“').alignment = Alignment(horizontal='center', vertical='center')
                    summary_sheet.cell(row=2, column=start_col + 1, value='åŠæˆå“').alignment = Alignment(horizontal='center', vertical='center')
                
                    for row_idx in range(3, summary_sheet.max_row + 1):
                        summary_wf = summary_sheet.cell(row=row_idx, column=1).value
                        summary_spec = summary_sheet.cell(row=row_idx, column=2).value
                        summary_prod = summary_sheet.cell(row=row_idx, column=3).value
                
                        # ç›´æ¥æ‰¾æˆå“
                        match = product_in_progress_pivoted[
                            (product_in_progress_pivoted['æ™¶åœ†å‹å·'].astype(str) == str(summary_wf)) &
                            (product_in_progress_pivoted['äº§å“è§„æ ¼'].astype(str) == str(summary_spec)) &
                            (product_in_progress_pivoted['äº§å“å“å'].astype(str) == str(summary_prod))
                        ]
                
                        finished_value = match[numeric_cols].sum(axis=1).values[0] if not match.empty else 0

                        # å…ˆæ‰¾ mapping è¡¨ä¸­æ»¡è¶³æ™¶åœ†å“åã€è§„æ ¼ã€å“åã€ä¸”åŠæˆå“åˆ—éç©ºçš„è¡Œ
                        semi_match = df_full_mapping[
                            (df_full_mapping['æ–°æ™¶åœ†å“å'].astype(str) == str(summary_wf)) &
                            (df_full_mapping['æ–°è§„æ ¼'].astype(str) == str(summary_spec)) &
                            (df_full_mapping['åŠæˆå“'].notnull()) &
                            (df_full_mapping['åŠæˆå“'].astype(str) != '')
                        ]
                        
                        semi_finished_value = 0
                        
                        if not semi_match.empty:
                            semi_wafer = semi_match['æ–°æ™¶åœ†å“å'].values[0]
                            semi_spec = semi_match['æ–°è§„æ ¼'].values[0]
                            semi_prod = semi_match['æ–°å“å'].values[0]
                        
                            # æ‰“å° mapping è¡¨åŒ¹é…åˆ°çš„åŠæˆå“ key
                            st.write(f"âœ… Mapping åŒ¹é…åˆ°åŠæˆå“ â†’ æ™¶åœ†å‹å·: {semi_wafer}, äº§å“è§„æ ¼: {semi_spec}, äº§å“å“å: {semi_prod}")
                        
                            semi_row = product_in_progress_pivoted[
                                (product_in_progress_pivoted['æ™¶åœ†å‹å·'].astype(str) == str(semi_wafer)) &
                                (product_in_progress_pivoted['äº§å“è§„æ ¼'].astype(str) == str(semi_spec)) &
                                (product_in_progress_pivoted['äº§å“å“å'].astype(str) == str(semi_prod))
                            ]
                        
                            if not semi_row.empty:
                                semi_finished_value = semi_row[numeric_cols].sum(axis=1).values[0]
                        
                                # æ‰“å°æˆå“ â†’ åœ¨æˆå“åœ¨åˆ¶é‡Œæ‰¾åˆ°äº†åŠæˆå“å¯¹åº”è¡Œçš„æç¤º
                                st.write(f"ğŸ¯ æˆå“ â†’ åœ¨æˆå“åœ¨åˆ¶é‡Œæ‰¾åˆ°äº†åŠæˆå“è¡Œ â†’ æˆå“: {summary_wf}, {summary_spec}, {summary_prod} | åŠæˆå“: {semi_wafer}, {semi_spec}, {semi_prod}")
                            else:
                                semi_finished_value = 0
                        
                                # æ‰“å°æˆå“ â†’ æ²¡æ‰¾åˆ°åŠæˆå“å¯¹åº”è¡Œçš„æç¤º
                                st.write(f"âš ï¸ æˆå“ â†’ æ²¡åœ¨æˆå“åœ¨åˆ¶é‡Œæ‰¾åˆ°åŠæˆå“è¡Œ â†’ æˆå“: {summary_wf}, {summary_spec}, {summary_prod} | åŠæˆå“: {semi_wafer}, {semi_spec}, {semi_prod}")

                        
                        # å†™å…¥åˆ°æ±‡æ€»è¡¨
                        summary_sheet.cell(row=row_idx, column=start_col, value=finished_value)
                        summary_sheet.cell(row=row_idx, column=start_col + 1, value=semi_finished_value)
                
                        # æ ‡è®°æˆå“åŒ¹é…
                        if not match.empty:
                            product_in_progress_pivoted.loc[match.index, 'å·²åŒ¹é…'] = True
                        if not semi_row.empty:
                            product_in_progress_pivoted.loc[semi_row.index, 'å·²åŒ¹é…'] = True
                
                    # åœ¨èµ›å“-æˆå“åœ¨åˆ¶ sheet ä¸­æ ‡çº¢æœªåŒ¹é…è¡Œ
                    in_progress_sheet = writer.book['èµ›å“-æˆå“åœ¨åˆ¶']
                    for row_idx, matched in enumerate(product_in_progress_pivoted['å·²åŒ¹é…'], start=2):
                        if not matched:
                            for col_idx in range(1, len(product_in_progress_pivoted.columns) + 1):
                                in_progress_sheet.cell(row=row_idx, column=col_idx).fill = PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid")



                # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                for idx, col in enumerate(worksheet.columns, 1):
                    col_letter = get_column_letter(idx)
                    max_length = 0
                    for cell in col:
                        try:
                            if cell.value:
                                cell_len = sum(2 if ord(char) > 127 else 1 for char in str(cell.value))
                                max_length = max(max_length, cell_len)
                        except:
                               pass
                    worksheet.column_dimensions[col_letter].width = max_length + 5

            # === åœ¨æ±‡æ€» sheet åŠ é»‘æ¡† ===
            summary_sheet = writer.book['æ±‡æ€»']
            # å‡è®¾å‰ä¸¤è¡Œæ˜¯æ ‡é¢˜
            max_row = 2  
            max_col = summary_sheet.max_column
            add_black_border(summary_sheet, max_row, max_col)

                    



        # ä¸‹è½½æŒ‰é’®
        with open(CONFIG['output_file'], 'rb') as f:
            st.download_button('ä¸‹è½½æ±‡æ€»æŠ¥å‘Š', f, CONFIG['output_file'])



if __name__ == '__main__':
    main()
